---
layout: post
comments: true
title: VQPy
author: Pengzhan Zhao, Shi Liu
date: 2022-04-24
---


> Video analytics has been gaining popularity in recent years, due to easier production of videos as well as development in computer vision algorithms and computing hardware. Traditional video analytics pipelines require developers to spend a lot of time on model optimizations, and can be difficult to reuse. Efforts such as SQL-like languages have tried to approach this problem, but only solved part of it, due to restrictions such as limited expressiveness. We propose to implement a Python dialect called VQPy, as an attempt to make video queries easier even for people with no CV-related knowledge, with its familiar programming interface and powerful object-oriented programming model.

<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Introduction

Video analytics applications have been ubiquitous nowadays. Millions of cameras are recording around the world, and diverse analytics programs are running in the background to achieve different functionalities. For example, speeding vehicles can be automatically detected from road surveillance videos, and the administration staff can send speeding tickets to vehicle owners based on the number badge; fall detection can recognize people potentially falling, so medical professionals can take earliest actions to prevent injuries [1]; also, train stations and airports can utilize video analytics to find unattended luggages for travellers [2].

A video analytics appllication is usually a compound process, including several different tasks organized in a certain order. Take speeding detection as example, it needs object detection to recognize vehicles and badges, uses object tracking to track speed of the vehicles, and utilize text recognition to identify badge numbers based on badge images. The good news is, for each procedure, we already have lots of models to use, such as R-CNN and YOLO for object detection, ByteTrack and TransMOT for object tracking, and classification models like CNNs for text recognition. However, which models to use for each task is not obvious, given the diverse charracteristics of data sets and goals of the user. Also, each model needs to be carefully trained and hyper-parameter needs to be tuned to achieve the best results. How to connect the models and how to transfer data between different models are also critical questions to answer. All problems mentioned above make the implementation of a video analytics application time-consuming and require expert knowledge.

Besides difficulties of implementation, video analytics applications are also faced with challenges when it comes to reusability. Let us see that now you have already implemented a video analytics pipeline, which can find all speeding trucks in white. What if now we want to have a new pipeline, whose goal is not a subset of that of our current pipeline, such as all speeding vehicles and all vehicles higher than 13ft in blue? If not carefully designed, modules in the existing pipeline can be tightly coupled, making reuse of it require intrusive modifications, further increasing time taken to build different queries.

There have been efforts trying to solve the problems, among which SQL-like languages for video analytics have gone the furthest. Take Blazelt [3] as an example, it treats camera framces as relation tables, and allows users to use SQL-like syntax to query frames which satisfy certain conditions. Examples of queries with VQPy are shown below in Figure 1. It comes with two major benefits: First, it supports some degree of modularity and reusability. Complex queries can be constructed with simple queries. Also, it relieves the burden of users to understand the implementation details. Instead, the user simply declare its goal. All procedures to select and generate the model pipeline is done by the SQL executor. Various optimizations can be made in the background for optimal performance. However, SQL-like languages still come with a major drawback: Its expressiveness is limited. When these languages treats different frames in a video as different records in a relation table, it is easy to query information on each frame, but is much harder to express queries which needs information from different frames, such as tracking an object.

![]({{ '/assets/images/team15/blazelt.png' | relative_url }})
{: style="width: 800px; max-width: 100%;"}
*Figure 1. Examples of Video Queries with Blazelt.*

To push the idea of video query language even further for a more complete expressiveness and ease of use, we purpose a new video query language, named VQPy. It is a Python dialect, implemented directly upon the standard Python, giving it broader expressiveness; Python is an object-oriented language, which means complex queries can be composed by simpler queries with class inheritance intuitively. Also, VQPy is designed as an high-level language, which means the application logic, i.e., what query to make, is separated from the underlying model implementation, just like the SQL-like languages.

An overview of a video query workflow with VQPy is shown below in Figure 2: First, user declare its goal with the query. Here the user wants to find all cars whose speed exceeds 75 in a set of frames. Then, VQPy will automatically generate logics regarding model selection and training. We also give users the option to state hints on the model information if they want to. The application logic code and the model logic code are fed into VQPy compiler, which generates the execution plan for the query.

![]({{ '/assets/images/team15/vqpy-overview.jpg' | relative_url }})
{: style="width: 800px; max-width: 100%;"}
*Figure 2. An Overview of Video Query Workflow with VQPy.*

With the power of VQPy, more complex features can be considered, such as queries upon multiple camera views, as well as queries on streaming data. We will start from simple occasions where VQPy can be used to make video queries easy for end users first, and expand the scope of the project as time permits.

## Language Design

TODO(Pengzhan)

## Current Progress

TODO(Pengzhan)

## References

1. Rougier, C., Meunier, J., St-Arnaud, A., & Rousseau, J. (2011). Robust video surveillance for fall detection based on human shape deformation. IEEE Transactions on circuits and systems for video Technology, 21(5), 611-622.
2. Unattended Baggage Detection Using Deep Neural Networks in Intel® Architecture, https://www.intel.com/content/www/us/en/artificial-intelligence/solutions/unattended-baggage-detection-using-deep-neural-networks.html
3. Daniel Kang, Peter Bailis, and Matei Zaharia. 2019. BlazeIt: optimizing declarative aggregation and limit queries for neural network-based video analytics. Proc. VLDB Endow. 13, 4 (December 2019), 533–546. DOI:https://doi.org/10.14778/3372716.3372725
